{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9b62c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] meta  saved: /Users/hiroyukiyamanaka/Desktop/python_stock/dash_plotly/data/parquet/core30_meta.parquet   rows=30\n",
      "[OK] prices saved: /Users/hiroyukiyamanaka/Desktop/python_stock/dash_plotly/data/parquet/core30_prices_1y_1d.parquet rows=7320\n",
      "[OK] manifest updated: /Users/hiroyukiyamanaka/Desktop/python_stock/dash_plotly/data/parquet/manifest.json\n",
      "[OK] uploaded: s3://dash-plotly/parquet/core30_meta.parquet\n",
      "[OK] uploaded: s3://dash-plotly/parquet/core30_prices_1y_1d.parquet\n",
      "[OK] uploaded: s3://dash-plotly/parquet/manifest.json\n"
     ]
    }
   ],
   "source": [
    "# === TOPIX Core 30 の株価(1y,1d)を取得して Parquet に保存 + manifest更新 + S3アップロード ===\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "\n",
    "# --- add for module path (nbconvert runs with cwd=analyze) ---\n",
    "import sys\n",
    "from pathlib import Path\n",
    "ROOT = Path.cwd().resolve().parent  # project root\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# ==== 共通設定/ユーティリティ（DRY） ====\n",
    "from common_cfg.env import load_dotenv_cascade\n",
    "from common_cfg.flags import NO_MANIFEST, NO_S3\n",
    "from common_cfg.paths import (\n",
    "    PARQUET_DIR,\n",
    "    WEIGHT_PARQUET,\n",
    "    OUT_PRICES,\n",
    "    OUT_META,\n",
    "    MANIFEST_PATH,\n",
    ")\n",
    "from common_cfg.s3cfg import DATA_BUCKET, PARQUET_PREFIX, AWS_REGION, AWS_PROFILE\n",
    "from common_cfg.manifest import sha256_of, write_manifest_atomic\n",
    "from common_cfg.s3io import maybe_upload_files_s3\n",
    "\n",
    "# .env 読み込み（.env.s3 → .env の順で存在すれば読み込み）\n",
    "load_dotenv_cascade()\n",
    "\n",
    "# ---- 読み込み（Core30 抽出）----\n",
    "if not WEIGHT_PARQUET.exists():\n",
    "    raise FileNotFoundError(f\"not found: {WEIGHT_PARQUET}\")\n",
    "\n",
    "w = pd.read_parquet(WEIGHT_PARQUET, engine=\"pyarrow\")\n",
    "for col in (\"code\", \"stock_name\", \"size_class\"):\n",
    "    if col not in w.columns:\n",
    "        raise KeyError(f\"required column missing: {col}\")\n",
    "\n",
    "w[\"code\"] = w[\"code\"].astype(\"string\")\n",
    "w[\"size_class\"] = w[\"size_class\"].astype(\"string\")\n",
    "\n",
    "# \"TOPIX Core30/Core 30\" 両対応（空白除去して包含判定）\n",
    "_mask_core30 = w[\"size_class\"].str.replace(\" \", \"\", regex=False).str.contains(\"Core30\", case=False, na=False)\n",
    "core = (\n",
    "    w.loc[_mask_core30, [\"code\", \"stock_name\"]]\n",
    "     .drop_duplicates(subset=[\"code\"])\n",
    "     .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "def _to_ticker(x: str) -> str:\n",
    "    s = str(x).strip()\n",
    "    return s if s.endswith(\".T\") else f\"{s}.T\"\n",
    "\n",
    "core[\"ticker\"] = core[\"code\"].map(_to_ticker)\n",
    "\n",
    "if core.empty:\n",
    "    raise RuntimeError(\"Core30 list is empty. Check 'size_class' values in topixweight_j.parquet.\")\n",
    "\n",
    "tickers = core[\"ticker\"].tolist()\n",
    "\n",
    "# ---- yfinance 取得（1y,1d）----\n",
    "def _flatten_multi(raw: pd.DataFrame, tickers: list[str]) -> pd.DataFrame:\n",
    "    frames = []\n",
    "    if isinstance(raw.columns, pd.MultiIndex):\n",
    "        for t in tickers:\n",
    "            if t in raw.columns.get_level_values(0):\n",
    "                sub = raw[t].copy()\n",
    "                if sub.empty:\n",
    "                    continue\n",
    "                sub = sub.reset_index()\n",
    "                if \"Date\" in sub.columns:\n",
    "                    sub = sub.rename(columns={\"Date\": \"date\"})\n",
    "                elif \"index\" in sub.columns:\n",
    "                    sub = sub.rename(columns={\"index\": \"date\"})\n",
    "                else:\n",
    "                    sub.columns = [\"date\"] + [c for c in sub.columns[1:]]\n",
    "                sub[\"ticker\"] = t\n",
    "                keep = [c for c in [\"date\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\",\"ticker\"] if c in sub.columns]\n",
    "                frames.append(sub[keep])\n",
    "    else:\n",
    "        sub = raw.reset_index()\n",
    "        if \"Date\" in sub.columns:\n",
    "            sub = sub.rename(columns={\"Date\": \"date\"})\n",
    "        elif \"index\" in sub.columns:\n",
    "            sub = sub.rename(columns={\"index\": \"date\"})\n",
    "        sub[\"ticker\"] = tickers[0] if tickers else \"UNKNOWN\"\n",
    "        keep = [c for c in [\"date\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\",\"ticker\"] if c in sub.columns]\n",
    "        frames.append(sub[keep])\n",
    "\n",
    "    if not frames:\n",
    "        return pd.DataFrame(columns=[\"date\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\",\"ticker\"])\n",
    "    out = pd.concat(frames, ignore_index=True)\n",
    "    # tz-aware → naive への安全化\n",
    "    if np.issubdtype(out[\"date\"].dtype, np.datetime64):\n",
    "        try:\n",
    "            out[\"date\"] = pd.to_datetime(out[\"date\"]).dt.tz_localize(None)\n",
    "        except Exception:\n",
    "            out[\"date\"] = pd.to_datetime(out[\"date\"], utc=True).dt.tz_localize(None)\n",
    "    else:\n",
    "        out[\"date\"] = pd.to_datetime(out[\"date\"], errors=\"coerce\")\n",
    "    for c in [\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]:\n",
    "        if c in out.columns:\n",
    "            out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "    return out\n",
    "\n",
    "try:\n",
    "    raw = yf.download(\n",
    "        tickers,\n",
    "        period=\"1y\",\n",
    "        interval=\"1d\",\n",
    "        group_by=\"ticker\",\n",
    "        threads=True,\n",
    "        progress=False,\n",
    "        auto_adjust=True, \n",
    "    )\n",
    "    prices = _flatten_multi(raw, tickers)\n",
    "    if prices.empty:\n",
    "        raise RuntimeError(\"yf.download returned empty. fallback to per-ticker.\")\n",
    "except Exception:\n",
    "    frames = []\n",
    "    for t in tickers:\n",
    "        try:\n",
    "            r = yf.download(t, period=\"1y\", interval=\"1d\", group_by=\"ticker\", threads=True, progress=False,auto_adjust=True)\n",
    "            f = _flatten_multi(r, [t])\n",
    "            if not f.empty:\n",
    "                frames.append(f)\n",
    "        except Exception:\n",
    "            pass\n",
    "    prices = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "\n",
    "need = {\"date\",\"Open\",\"High\",\"Low\",\"Close\",\"ticker\"}\n",
    "if prices.empty or not need.issubset(prices.columns):\n",
    "    raise RuntimeError(\"No price data collected or required columns missing.\")\n",
    "\n",
    "# ---- 保存 ----\n",
    "OUT_PRICES.parent.mkdir(parents=True, exist_ok=True)\n",
    "core.to_parquet(OUT_META, engine=\"pyarrow\", index=False)\n",
    "prices.to_parquet(OUT_PRICES, engine=\"pyarrow\", index=False)\n",
    "\n",
    "print(f\"[OK] meta  saved: {OUT_META}   rows={len(core)}\")\n",
    "print(f\"[OK] prices saved: {OUT_PRICES} rows={len(prices)}\")\n",
    "\n",
    "# ---- manifest 更新（抑止可能） ----\n",
    "if not NO_MANIFEST:\n",
    "    items = []\n",
    "    for p in [OUT_META, OUT_PRICES]:\n",
    "        stat = p.stat()\n",
    "        items.append({\n",
    "            \"key\": p.name,\n",
    "            \"bytes\": stat.st_size,\n",
    "            \"sha256\": sha256_of(p),\n",
    "            \"mtime\": pd.Timestamp(stat.st_mtime, unit=\"s\", tz=\"UTC\").isoformat(),\n",
    "        })\n",
    "    write_manifest_atomic(items, MANIFEST_PATH)\n",
    "    print(f\"[OK] manifest updated: {MANIFEST_PATH}\")\n",
    "else:\n",
    "    print(\"[INFO] PIPELINE_NO_MANIFEST=1 → manifest 更新はスキップ\")\n",
    "\n",
    "# ---- S3 アップロード（抑止可能）----\n",
    "_to_upload = [OUT_META, OUT_PRICES, MANIFEST_PATH] if not NO_MANIFEST else [OUT_META, OUT_PRICES]\n",
    "maybe_upload_files_s3(_to_upload, bucket=DATA_BUCKET, prefix=PARQUET_PREFIX,\n",
    "                      aws_region=AWS_REGION, aws_profile=AWS_PROFILE, dry_run=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a8afa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
